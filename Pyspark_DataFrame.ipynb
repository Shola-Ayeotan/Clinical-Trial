{"cells":[{"cell_type":"markdown","source":["Creating User-Defined Functions"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bc494298-674a-4884-b204-d36e96236fe4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Defining a function for splitting datasets\n \ndef splitting_data(dataset, delimiter):\n    return dataset.map(lambda line: line.split(delimiter))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7b7a8d10-a832-45f5-9e40-d2201bdae4ec","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Defining a function for removing headers \n\ndef removing_header(rdd):\n    header = rdd.first()\n    return rdd.filter(lambda row: row != header)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"acb86573-090d-44c5-a81f-3bfecd5723f8","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Loading Clinical data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"646c638f-c183-4e5b-973a-3841bd3a4c28","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Loading the CSV file as an RDD\nclinicaltrialRDD = sc.textFile(\"/FileStore/tables/clinicaltrial_2021.csv\")\n\n# Removing the header\nclinicaltrialRDD = removing_header(clinicaltrialRDD)\n\n# Removing the delimiter\nclinicaltrialRDD = splitting_data(clinicaltrialRDD, \"|\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c7bf884e-d92f-4dc0-b42a-4d9f4c2ed49b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["from pyspark.sql.types import *\n\n# Defining the schema for clinical trial data\nmySchema = StructType([\n    StructField(\"Id\", StringType(), True),\n    StructField(\"Sponsor\", StringType(), True),\n    StructField(\"Status\", StringType(), True),\n    StructField(\"Start\", StringType(), True),\n    StructField(\"Completion\", StringType(), True),\n    StructField(\"Type\", StringType(), True),\n    StructField(\"Submission\",StringType(), True),\n    StructField(\"Conditions\", StringType(), True),\n    StructField(\"Interventions\", StringType(), True)])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e2c780fc-8b70-480a-bfad-262c8f485eef","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Converting the RDD to a DataFrame with the specified schema\nclinicaltrialDF = spark.createDataFrame(clinicaltrialRDD, mySchema)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"2e4572f1-830e-453e-8311-302feb40004b","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Printing the schema\nclinicaltrialDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"fec26bb4-ad49-4f1e-a84c-2470da07be86","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Displaying the first 10 rows of the clinical trial data\nclinicaltrialDF.display(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c3761e4e-6a53-41b7-97f1-d1c0d2aeecc4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Loading Pharma data"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"fed16268-914f-4e85-9178-5e85257af95c","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Loading the pharma dataset\npharmaDF = spark.read.csv(\"/FileStore/tables/pharma.csv\", header=True, inferSchema=True)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"63303b0d-0e96-4cf8-88b6-b88518055e74","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Printing the schema of the Pharma DataFrame\npharmaDF.printSchema()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"16129cfc-8e3e-49a4-a66d-526ff3a13f8c","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Displaying the first 10 rows of the Pharma data\npharmaDF.display(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"56456326-e7d9-460f-a105-b0f3ce3f37a4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Question 1"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"5083caee-3747-4b8f-9531-27e2b39a4edf","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Selecting distinct values of the 'Id' column and counting it\nstudiesCountDF = clinicaltrialDF\\\n                    .select(\"Id\")\\\n                    .distinct()\\\n                    .count()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"57d2c4a9-38a1-451b-8c75-f06654d051d2","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Printing the result \nprint(\"The number of distinct studies conducted were:\", studiesCountDF)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"097fd97e-ecbf-475b-82fd-f8fd56ef2b03","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Question 2"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"da5abfc6-1edd-4bd6-8afa-56cfb405b084","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import count\n\n# Grouping the DataFrame by the 'Type' column and aggregating the count of each type\nstudytypesDF = clinicaltrialDF\\\n                    .groupBy(\"Type\")\\\n                    .agg(count(\"Type\").alias(\"Frequency\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c3cde9b9-2b26-42b7-9edb-fd547e24e4e4","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Sorting the resulting DataFrame by the 'Frequency' column in descending order\nstudytypesDF = studytypesDF.orderBy(\"Frequency\", ascending=False)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4cf5aefc-3f35-4fb3-985a-9652426d38af","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Displaying the result\nstudytypesDF.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"b6fb02ff-a593-4af3-8951-3ca704d2a3a1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Visualization"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"091798e5-e74b-4272-98ee-ae0399ad70eb","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Converting the DataFrame to a Pandas DataFrame\nstudytypesPandasDF = studytypesDF.toPandas()\n\n# Creating a bar chart using the resulting Pandas DataFrame\nfig = plt.figure(figsize=(10, 5))\nstudytypesPandasDF.plot(kind='barh', x='Type', y='Frequency')\n\n# Setting the title and axes labels\nplt.title(\"Number of Clinical Trials by Type in 2021\")\nplt.xlabel(\"Type\")\nplt.ylabel(\"Frequency\")\n\n# Rotating the x-axis labels for better visibility\nplt.xticks(rotation=90)\n\n# Displaying the bar chart\nplt.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"55a51360-4fc4-41ee-8168-a24974573773","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Question 3"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1c06b81b-ae6e-4cfa-b2bc-bb128c9648f0","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Importing necessary functions\nfrom pyspark.sql.functions import split, explode, count\n\n# Splitting the 'Conditions' column \nconditionsDF = clinicaltrialDF \\\n               .withColumn(\"condition\", explode(split(\"Conditions\", \",\")))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"3b3a23bb-df81-40db-9da8-ffa30e36a2fc","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Filtering out any empty conditions\nconditionsDF = conditionsDF.filter(\"condition != ''\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c078941c-a913-40b7-b57f-4635de35f18e","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Grouping by the \"condition\" column and counting the frequency of each condition\ntopConditionsDF = conditionsDF \\\n                  .groupBy(\"condition\") \\\n                  .agg(count(\"*\").alias(\"frequency\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"024090bc-6b97-416a-afe2-eae20b20530a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Ordering the resulting DataFrame by frequency and selecting the top 5 rows\ntopConditionsDF = topConditionsDF.orderBy(\"frequency\", ascending=False).limit(5)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"458cbe21-9271-4c1b-996b-9fdaced0be51","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Displaying the resulting DataFrame\ntopConditionsDF.display()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4f1065b7-8453-416b-9917-e6339818214d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Visualization"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"29a734dd-9595-4f4d-b190-228aa4ba79bc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Converted the PySpark DataFrame to a Pandas DataFrame\ntopConditionsPandasDF = topConditionsDF.toPandas()\n\n# Created a bar chart using Seaborn\nsns.set_style(\"whitegrid\")\nplt.figure(figsize=(10, 5))\nax = sns.barplot(x=\"frequency\", y=\"condition\", data=topConditionsPandasDF, color=\"b\")\n\n# Set the chart title and axes labels\nplt.title(\"Top 5 Conditions in Clinical Trials in 2021\")\nplt.xlabel(\"Frequency\")\nplt.ylabel(\"Condition\")\n\n# Displayed the chart\nplt.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"bf709de3-733d-4c3b-a6f0-4df31ea2f0c1","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Question 4"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"036b9a04-559c-4a87-90eb-48a0a74fb0bc","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import count\n\n# Joining the Clinicaltrial and Pharma DataFrames using a left join \nnonPharmaSponsors = clinicaltrialDF \\\n                    .join(pharmaDF, clinicaltrialDF.Sponsor == pharmaDF[\"Parent_Company\"], \"left_anti\")"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"4f376fdc-2529-4ed5-9e29-d1ea082c1dab","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Grouping and counting the clinical trials sponsored by non-pharma companies\ntopSponsors = nonPharmaSponsors\\\n               .groupBy(\"Sponsor\")\\\n               .agg(count(\"Sponsor\").alias(\"sponsored_trials\"))\\\n               .orderBy(\"sponsored_trials\", ascending=False)\\\n               .take(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1a0b5036-9f92-4729-9159-b1ab8465ffca","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Printing the top 10 sponsors \nprint(\"These are the top 10 sponsors that are not pharmaceutical companies:\")\nfor sponsor, count_col in topSponsors:\n    print(sponsor, count_col)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"508da489-0de4-4b73-bfb4-d35d21bbcb86","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Visualization"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"45e0a0a7-948a-4d2f-ae78-19d975fe759f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Convert topSponsors list to a pandas DataFrame\ntopSponsorsDF = pd.DataFrame(topSponsors, columns=[\"Sponsor\", \"sponsored_trials\"])\n\n# Create a line chart of sponsor counts\nplt.plot(topSponsorsDF[\"Sponsor\"], topSponsorsDF[\"sponsored_trials\"])\nplt.xticks(rotation=90)\nplt.title(\"Top 10 Non-Pharmaceutical Sponsors\")\nplt.xlabel(\"Sponsors\")\nplt.ylabel(\"Number of sponsored trials\")\nplt.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"00c3a7fb-0e34-4661-84d5-25764184712f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["## Question 5"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"01a063a4-e240-4d77-971d-e44dc180b8b5","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Importing necessary functions\nfrom pyspark.sql.functions import to_date, year, month, date_format\n\n# Filtering to include only trials with a status of \"Completed\" and a completion year of 2021.\ncompletedTrialsDF = clinicaltrialDF \\\n                        .filter((clinicaltrialDF.Status == \"Completed\") \\\n                                & (year(to_date(clinicaltrialDF.Completion, \"MMM yyyy\")) == 2021))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1ba0693f-264b-40e2-a5ce-f3bf69223350","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Grouping tby month of completion and counting the number of trials for each month.\ncompletedCountsDF = completedTrialsDF \\\n                    .groupBy(date_format(to_date(completedTrialsDF.Completion, \"MMM yyyy\"), \"MMM\").alias(\"month\")) \\\n                    .count() \\\n                    .orderBy(month(\"month\"))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"f58e2ebf-4a9d-4088-8e57-b2686e306d9f","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Creating a dictionary mapping month abbreviations\nmonthDictionary = {\"Jan\": 1, \"Feb\": 2, \"Mar\": 3, \"Apr\": 4, \"May\": 5, \"Jun\": 6,\\\n                   \"Jul\": 7, \"Aug\": 8, \"Sep\": 9, \"Oct\": 10, \"Nov\": 11, \"Dec\": 12}"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"16a6ef89-d592-4267-a5c8-bd78e70d9e2a","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Sorting the results using the creatd month dictionary.\nresults = completedCountsDF.collect()\nresults = sorted(results, key=lambda x: monthDictionary[x[0]])"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"33024c40-2ec8-4172-a360-fcefa807f311","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# Printed the results\nfor (month, count) in results:\n    print(\"{:<3} {}\".format(month, count))"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c29a2d77-0ae9-4e8c-8379-f457de6dba4d","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Visualization"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"9425390b-9a0e-4cfb-a08e-afdd026ce961","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n\n# Extract the month names and counts into separate lists\nmonths = [x[0] for x in results]\ncounts = [x[1] for x in results]\n\n# Plot the data as a bar chart\nplt.bar(months, counts)\n\n# Set the x-label and y-label\nplt.xlabel(\"Month\")\nplt.ylabel(\"Number of Completed Trials\")\n\n# Set the title\nplt.title(\"Completed Clinical Trials in 2021\")\n\n# Show the plot\nplt.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1c795c2a-525b-4004-8271-f451d8363885","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Further Analysis 2 (DataFrame)\n\nInvestigate the distribution of trial statuses across different types of studies. \n\nWhat are the top 10 Type-Status combinations and their respective counts in the clinical trial dataset?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"fefee10a-1406-4e35-868f-5fe4f43fd7a4","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import count\n\n# grouping by Type/Status and counting the number of trials for each combination\nstatusDF = clinicaltrialDF.groupBy(\"Type\", \"Status\").agg(count(\"*\").alias(\"Count\"))\n\n# sorting the count in descending order\nstatusCountDF = statusDF.orderBy(\"Count\", ascending=False)\n\n# Selecting the top 10 Type/Status combinations\nstatusCountDF.show(10)"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7384f90d-352b-48a4-be0b-3a6d7ac242dd","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["##### Visualization"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"6285de4f-426a-410b-8b79-e3a299a1dc0a","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["import pandas as pd\nimport matplotlib.pyplot as plt\n\n# Converting statusCountDF to a pandas DataFrame\nstatusCountPandasDF = statusCountDF.toPandas()\n\n# Extracting the top 10 rows\ntop10 = statusCountPandasDF.head(10)\n\n# Pivoting the data to create a grouped bar chart\ngroupedData = top10.pivot(index=\"Type\", columns=\"Status\", values=\"Count\")\n\n# Creating the chart\ngroupedData.plot(kind=\"bar\")\nplt.title(\"Top 10 Type-Status Combinations\")\nplt.xlabel(\"Type\")\nplt.ylabel(\"Count\")\nplt.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"abda4f07-a0ad-4206-b266-f11342f85daf","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Extra Feature\n\nColumn Count Function"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"370f3d7b-5b35-4955-ae83-2384427f567f","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["from pyspark.sql.functions import count\n\ndef columnCount(df, col_name):\n    \n    # Grouping the data by input column and counting the rows\n    countDF = df.groupBy(col_name).agg(count(\"*\").alias(\"count\"))\n\n    # Sorting the data in descending order\n    countDF = countDF.orderBy(\"count\", ascending=False)\n\n    return countDF\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"407626ad-b8c6-445d-a0d5-e5089ff25d38","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["#### Question 1\nIdentify the relationship between the origin of a parent company (HQ_Country_of_Parent) and the number of violations?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"e4c64d6a-bad8-471b-b173-0b92d82cb0ee","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Calling the function on the Pharma dataframe\nviolationsDF = columnCount(pharmaDF, \"HQ_Country_of_Parent\")\n\n# Displaying the results\nviolationsDF.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"c1e3403c-7ac2-4d45-a92d-ac502b428ce9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["import seaborn as sns\n\nsns.set_style('darkgrid')\n\nplt.figure(figsize=(14, 8))\nsns.barplot(data=violationsDF.toPandas(), x='HQ_Country_of_Parent', y='count')\nplt.title('Number of Violations by Country of Parent Compamy')\nplt.xlabel('Country of Parent Company')\nplt.ylabel('Number of Violations')\nplt.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"957aeef7-306a-49a4-9bdf-49b90d6b73e9","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"markdown","source":["### Question 2\nInvestigate the distribution of violations during the years. \nWhich year experienced the biggest spike in violations?"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"725fa347-f0fb-40b7-9c1b-7a89ad4788ef","inputWidgets":{},"title":""}}},{"cell_type":"code","source":["# Calling the function ColumnCount function on the dataframe\nyearly_violations = columnCount(pharmaDF, \"Penalty_Year\")\nyearly_violations.show()"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"1739925b-a36c-4eb3-8575-4b6cce656d26","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0},{"cell_type":"code","source":["# converting the DataFrame to a Pandas DataFrame\nyearly_violationspd = yearly_violations.toPandas()\n\n# plotting the line chart with a trend line\nfig, ax = plt.subplots(figsize=(12,6))\nsns.regplot(data=yearly_violationspd, x='Penalty_Year', y='count', ax=ax)\nplt.title(\"Trend of violations made per year\")\nplt.xlabel(\"Year\")\nplt.ylabel(\"Number of Violations\")\nplt.show()\n"],"metadata":{"application/vnd.databricks.v1+cell":{"showTitle":false,"cellMetadata":{"rowLimit":10000,"byteLimit":2048000},"nuid":"7cf9752b-bfb3-4403-8a92-63a01c582bd7","inputWidgets":{},"title":""}},"outputs":[],"execution_count":0}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"Shola_Ayeotan_DF","dashboards":[],"notebookMetadata":{"pythonIndentUnit":4},"language":"python","widgets":{},"notebookOrigID":175714116764133}},"nbformat":4,"nbformat_minor":0}
